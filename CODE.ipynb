{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "dTYNiQZmYE5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "mounted_dir = '/content/drive/'\n",
        "drive.mount(mounted_dir, force_remount=True)"
      ],
      "metadata": {
        "id": "t8ea09EXYGOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# project folder path in GDrive\n",
        "project_dir = ''\n",
        "\n",
        "# you need to have three folders inside the project folder:\n",
        "# Stimulus: it contains the stimulus of the experiment\n",
        "# MEG: it contains the MEG files of an anonymous subject\n",
        "# Result: the results will be saved in this folder\n",
        "full_image_path = os.path.join(mounted_dir, 'MyDrive', project_dir, 'Stimulus')\n",
        "full_raw_path = os.path.join(mounted_dir, 'MyDrive', project_dir, 'MEG')\n",
        "full_output_path = os.path.join(mounted_dir, 'MyDrive', project_dir, 'Result')"
      ],
      "metadata": {
        "id": "af5FvfHsYIsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Features from AlexNet"
      ],
      "metadata": {
        "id": "F7IyYmbPjIl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install THINGSvision and dependencies"
      ],
      "metadata": {
        "id": "vRrxUopqjPWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade thingsvision\n",
        "\n",
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "kwieHA6CjSqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import alexnet\n",
        "from thingsvision import get_extractor\n",
        "from thingsvision import get_extractor_from_model\n",
        "from thingsvision.utils.storing import save_features\n",
        "from thingsvision.utils.data import ImageDataset, DataLoader\n",
        "from thingsvision.core.extraction import center_features\n",
        "from thingsvision.core.rsa import compute_rdm\n",
        "from typing import Any, List"
      ],
      "metadata": {
        "id": "N6i1dDVajUVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions to extract features"
      ],
      "metadata": {
        "id": "HZ1UHu7zjauL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(\n",
        "                    extractor: Any,\n",
        "                    module_name: str,\n",
        "                    image_path: str,\n",
        "                    out_path: str,\n",
        "                    batch_size: int,\n",
        "                    flatten_activations: bool,\n",
        "                    apply_center_crop: bool,\n",
        "                    class_names: List[str]=None,\n",
        "                    file_names: List[str]=None,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Extract features for a single layer.\"\"\"\n",
        "    dataset = ImageDataset(\n",
        "        root=image_path,\n",
        "        out_path=out_path,\n",
        "        backend=extractor.get_backend(),\n",
        "        transforms=extractor.get_transformations(apply_center_crop=apply_center_crop),\n",
        "        class_names=class_names,\n",
        "        file_names=file_names,\n",
        "    )\n",
        "    batches = DataLoader(dataset=dataset, batch_size=batch_size, backend=extractor.get_backend())\n",
        "    features = extractor.extract_features(\n",
        "                    batches=batches,\n",
        "                    module_name=module_name,\n",
        "                    flatten_acts=flatten_activations,\n",
        "    )\n",
        "    return features"
      ],
      "metadata": {
        "id": "fB4b5CNKjkGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "aYsWbztWj2Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained = True # use pretrained model weights\n",
        "model_path = None # if pretrained = False (i.e., randomly initialized weights) set path to model weights\n",
        "batch_size = 16 # use a power of two (this can be any size, depending on the number of images for which you aim to extract features)\n",
        "apply_center_crop = False # center crop images (set to False, if you don't want to center-crop images)\n",
        "flatten_activations = True # whether or not features (e.g., of Conv layers) should be flattened\n",
        "class_names = None  # optional list of class names for class dataset\n",
        "file_names = None # optional list of file names according to which features should be sorted\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "vqo8h_tFj4JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load AlexNet"
      ],
      "metadata": {
        "id": "aVM0i3Cbj9Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'alexnet'\n",
        "module_name = 'features.12'\n",
        "\n",
        "# specify model source\n",
        "source = 'torchvision'\n",
        "# initialize the extractor\n",
        "extractor = get_extractor(\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            model_path=model_path,\n",
        "            device=device,\n",
        "            source=source)"
      ],
      "metadata": {
        "id": "zBSPeiY7j_gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features for a single layer"
      ],
      "metadata": {
        "id": "NoJwfAcwkWjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_alexnet = extract_features(\n",
        "                            extractor=extractor,\n",
        "                            module_name=module_name,\n",
        "                            image_path=full_image_path,\n",
        "                            out_path=full_output_path,\n",
        "                            batch_size=batch_size,\n",
        "                            flatten_activations=flatten_activations,\n",
        "                            apply_center_crop=apply_center_crop,\n",
        "                            class_names=class_names,\n",
        "                            file_names=file_names)\n",
        "\n",
        "# apply centering (not necessary, but may be desirable, depending on the analysis)\n",
        "features_alexnet = center_features(features_alexnet)\n",
        "\n",
        "# save features to disk\n",
        "save_features(features_alexnet, out_path=f'{full_output_path}/features_{model_name}_{module_name}', file_format='npy')"
      ],
      "metadata": {
        "id": "hnIrDen4kaH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load extracted features"
      ],
      "metadata": {
        "id": "TXkD9KBrz-Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_alexnet = np.load(f'{full_output_path}/features_{model_name}_{module_name}/features.npy', encoding='bytes')"
      ],
      "metadata": {
        "id": "eiOO_0nB0BVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create RDM"
      ],
      "metadata": {
        "id": "29m4iYfS6kT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# average every 100 rows\n",
        "features_alexnet_sum = 0\n",
        "\n",
        "for i in range(100):\n",
        "  features_alexnet_sum = features_alexnet[i::100] + features_alexnet_sum\n",
        "\n",
        "# create the RDM\n",
        "rdm_dnn = compute_rdm(features_alexnet_sum/100, method='correlation')"
      ],
      "metadata": {
        "id": "Be8NJmyq6nil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize RDM"
      ],
      "metadata": {
        "id": "cOzrMvjX7aBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4), dpi=200)\n",
        "plt.imshow(rdm_dnn.reshape(rdm_dnn.shape))"
      ],
      "metadata": {
        "id": "7DZgATxt7cNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Features from MEG"
      ],
      "metadata": {
        "id": "wBVaYPzpoaGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install MNE-Python and dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "YBVBZPIf4duu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "id": "KfRhJ_xl40yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import mne\n",
        "from mne.io import read_raw_fif"
      ],
      "metadata": {
        "id": "lI9C_KWv4rq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read raw file and create epochs"
      ],
      "metadata": {
        "id": "k_lhrNP65HX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_1 = read_raw_fif(full_raw_path+'/raw_1.fif', verbose='error', preload=True).pick_types(meg='mag', stim=True, eeg=False, eog=False)\n",
        "raw_2 = read_raw_fif(full_raw_path+'/raw_2.fif', verbose='error', preload=True).pick_types(meg='mag', stim=True, eeg=False, eog=False)\n",
        "raw_3 = read_raw_fif(full_raw_path+'/raw_3.fif', verbose='error', preload=True).pick_types(meg='mag', stim=True, eeg=False, eog=False)\n",
        "raw_4 = read_raw_fif(full_raw_path+'/raw_4.fif', verbose='error', preload=True).pick_types(meg='mag', stim=True, eeg=False, eog=False)\n",
        "raw_5 = read_raw_fif(full_raw_path+'/raw_5.fif', verbose='error', preload=True).pick_types(meg='mag', stim=True, eeg=False, eog=False)\n",
        "raw_6 = read_raw_fif(full_raw_path+'/raw_6.fif', verbose='error', preload=True).pick_types(meg='mag', stim=True, eeg=False, eog=False)\n",
        "\n",
        "# smooth the data\n",
        "raw_1.savgol_filter(10, verbose=None)\n",
        "raw_2.savgol_filter(10, verbose=None)\n",
        "raw_3.savgol_filter(10, verbose=None)\n",
        "raw_4.savgol_filter(10, verbose=None)\n",
        "raw_5.savgol_filter(10, verbose=None)\n",
        "raw_6.savgol_filter(10, verbose=None)\n",
        "\n",
        "# downsample the data\n",
        "desired_sfreq = 200\n",
        "current_sfreq = raw_1.info['sfreq']\n",
        "decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
        "obtained_sfreq = current_sfreq / decim\n",
        "lowpass_freq = obtained_sfreq / 3.\n",
        "raw_1.filter(l_freq=None, h_freq=lowpass_freq)\n",
        "raw_2.filter(l_freq=None, h_freq=lowpass_freq)\n",
        "raw_3.filter(l_freq=None, h_freq=lowpass_freq)\n",
        "raw_4.filter(l_freq=None, h_freq=lowpass_freq)\n",
        "raw_5.filter(l_freq=None, h_freq=lowpass_freq)\n",
        "raw_6.filter(l_freq=None, h_freq=lowpass_freq)\n",
        "\n",
        "# concatenate raws\n",
        "raw = raw_1\n",
        "raw.append(raw_2)\n",
        "raw.append(raw_3)\n",
        "raw.append(raw_4)\n",
        "raw.append(raw_5)\n",
        "raw.append(raw_6)\n",
        "del raw_1, raw_2, raw_3, raw_4, raw_5, raw_6\n",
        "\n",
        "# create events\n",
        "events = mne.find_events(raw, stim_channel='STI101', min_duration=.005, shortest_event=1, output='onset')\n",
        "\n",
        "# create epochs\n",
        "event_sample_dict = {'N1S1TFA1':1, 'N1S1TFA2':2, 'N1S2TFA1':3, 'N1S2TFA2':4,\n",
        "                     'N1S3TFA1':5, 'N1S3TFA2':6, 'N1S4TFA1':7, 'N1S4TFA2':8,\n",
        "                     'N2S1TFA1':9, 'N2S1TFA2':10, 'N2S2TFA1':11, 'N2S2TFA2':12,\n",
        "                     'N2S3TFA1':13, 'N2S3TFA2':14, 'N2S4TFA1':15, 'N2S4TFA2':16,\n",
        "                     'N3S1TFA1':17, 'N3S1TFA2':18, 'N3S2TFA1':19, 'N3S2TFA2':20,\n",
        "                     'N3S3TFA1':21, 'N3S3TFA2':22, 'N3S4TFA1':23, 'N3S4TFA2':24,\n",
        "                     'N4S1TFA1':25, 'N4S1TFA2':26, 'N4S2TFA1':27, 'N4S2TFA2':28,\n",
        "                     'N4S3TFA1':29, 'N4S3TFA2':30, 'N4S4TFA1':31, 'N4S4TFA2':32}\n",
        "epochs = mne.Epochs(raw, events, event_id=event_sample_dict, baseline=(-0.1,0), tmin=-0.1, tmax=0.8, decim=decim)\n",
        "epochs.equalize_event_counts()"
      ],
      "metadata": {
        "id": "-6qYvuIF5Hr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize average of each sample"
      ],
      "metadata": {
        "id": "6Ckg0Tlg6ElI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs.average().plot_joint(picks='mag')"
      ],
      "metadata": {
        "id": "bedRDOjy406o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_events, n_channels, n_times = epochs.get_data(picks='mag').shape\n",
        "print(f\"Number of Events: {n_events}, Number of Channels (Mag): {n_channels}, Time Points: {n_times}\")"
      ],
      "metadata": {
        "id": "LMD7c182EbCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install RSAToolbox and dependencies\n"
      ],
      "metadata": {
        "id": "-UtDpIivD7-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rsatoolbox"
      ],
      "metadata": {
        "id": "iHumFwU4EC7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rsatoolbox\n",
        "from rsatoolbox.rdm import calc_rdm_movie\n",
        "from scipy.spatial.distance import squareform"
      ],
      "metadata": {
        "id": "FTld6jceEROi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create RDMs"
      ],
      "metadata": {
        "id": "Bw-1EBvh8CQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_sample_list = ['N1S1TFA1', 'N1S1TFA2', 'N1S2TFA1', 'N1S2TFA2',\n",
        "                      'N1S3TFA1', 'N1S3TFA2', 'N1S4TFA1', 'N1S4TFA2',\n",
        "                      'N2S1TFA1', 'N2S1TFA2', 'N2S2TFA1', 'N2S2TFA2',\n",
        "                      'N2S3TFA1', 'N2S3TFA2', 'N2S4TFA1', 'N2S4TFA2',\n",
        "                      'N3S1TFA1', 'N3S1TFA2', 'N3S2TFA1', 'N3S2TFA2',\n",
        "                      'N3S3TFA1', 'N3S3TFA2', 'N3S4TFA1', 'N3S4TFA2',\n",
        "                      'N4S1TFA1', 'N4S1TFA2', 'N4S2TFA1', 'N4S2TFA2',\n",
        "                      'N4S3TFA1', 'N4S3TFA2', 'N4S4TFA1', 'N4S4TFA2']\n",
        "\n",
        "data = rsatoolbox.data.TemporalDataset(epochs.get_data(),\n",
        "                                       channel_descriptors={'names': epochs.ch_names},\n",
        "                                       obs_descriptors={'stimulus': event_sample_list},\n",
        "                                       time_descriptors={'time': epochs.times})\n",
        "\n",
        "rdms = rsatoolbox.rdm.calc.calc_rdm_movie(data,\n",
        "                                          method='euclidean',\n",
        "                                          descriptor=None,\n",
        "                                          noise=None,\n",
        "                                          cv_descriptor=None,\n",
        "                                          prior_lambda=1,\n",
        "                                          prior_weight=0.1,\n",
        "                                          time_descriptor='time',\n",
        "                                          bins=None)"
      ],
      "metadata": {
        "id": "-hltqG0b8ETi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper function to visualize the RDMs"
      ],
      "metadata": {
        "id": "Z849XDNTdmst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "def plot_rdm_movie(rdms_data: rsatoolbox.rdm.RDMs,\n",
        "                   descriptor: str,\n",
        "                   n_t_display:int = 20, #\n",
        "                   fig_width: Optional[int] = None,\n",
        "                   timecourse_plot_rel_height: Optional[int] = None,\n",
        "                   time_formatted: Optional[List[str]] = None,\n",
        "                   colored_conditions: Optional[list] = None,\n",
        "                   plot_individual_dissimilarities: Optional[bool] = None,\n",
        "                   ):\n",
        "    \"\"\" plots the RDM movie for a given descriptor\n",
        "\n",
        "    Args:\n",
        "        rdms_data (rsatoolbox.rdm.RDMs): rdm movie\n",
        "        descriptor (str): name of the descriptor that created the rdm movie\n",
        "        n_t_display (int, optional): number of RDM time points to display. Defaults to 20.\n",
        "        fig_width (int, optional):  width of the figure (in inches). Defaults to None.\n",
        "        timecourse_plot_rel_height (int, optional): height of the timecourse plot (relative to the rdm movie row).\n",
        "        time_formatted (List[str], optional): time points formatted as strings.\n",
        "            Defaults to None (i.e., rdms_data.time_descriptors['time'] is considered to be in seconds)\n",
        "        colored_condiitons (list, optional): vector of pattern condition names to dissimilarities according to a categorical model on colored_conditions Defaults to None.\n",
        "        plot_individual_dissimilarities (bool, optional): whether to plot the individual dissimilarities. Defaults to None (i.e., False if colored_conditions is notNone, True otherwise).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[matplotlib.figure.Figure, npt.ArrayLike, collections.defaultdict]:\n",
        "\n",
        "        Tuple of\n",
        "            - Handle to created figure\n",
        "            - Subplot axis handles from plt.subplots.\n",
        "    \"\"\"\n",
        "    # create labels\n",
        "    times = rdms_data.rdm_descriptors['time']\n",
        "    unique_time = np.unique(times)\n",
        "    time_formatted = time_formatted or ['%0.0f ms' % (np.round(x*1000,2)) for x in unique_time]\n",
        "\n",
        "    n_dissimilarity_elements = rdms_data.dissimilarities.shape[1]\n",
        "\n",
        "    # color mapping from colored conditions\n",
        "    unsquareform = lambda a: a[np.nonzero(np.triu(a, k=1))]\n",
        "    if colored_conditions is not None:\n",
        "        plot_individual_dissimilarities = False if plot_individual_dissimilarities is None else plot_individual_dissimilarities\n",
        "        unsquare_idx = np.triu_indices(n_dissimilarity_elements, k=1)\n",
        "        pairwise_conds = unsquareform(np.array([[{c1, c2} for c1 in colored_conditions] for c2 in colored_conditions]))\n",
        "        pairwise_conds_unique = np.unique(pairwise_conds)\n",
        "        cnames = np.unique(colored_conditions)\n",
        "        color_index = {f'{list(x)[0]} vs {list(x)[1]}' if len(list(x))==2 else f'{list(x)[0]} vs {list(x)[0]}': pairwise_conds==x for x in pairwise_conds_unique}\n",
        "    else:\n",
        "        color_index = {'': np.array([True]*n_dissimilarity_elements)}\n",
        "        plot_individual_dissimilarities = True\n",
        "\n",
        "    colors = plt.get_cmap('turbo')(np.linspace(0, 1, len(color_index)+1))\n",
        "\n",
        "    # how many rdms to display\n",
        "    t_display_idx = (np.round(np.linspace(0, len(unique_time)-1, min(len(unique_time), n_t_display)))).astype(int)\n",
        "    t_display_idx = np.unique(t_display_idx)\n",
        "    n_t_display = len(t_display_idx)\n",
        "\n",
        "    # auto determine relative sizes of axis\n",
        "    timecourse_plot_rel_height = timecourse_plot_rel_height or n_t_display // 3\n",
        "    base_size = 40 / n_t_display if fig_width is None else fig_width / n_t_display\n",
        "\n",
        "    # figure layout\n",
        "    fig = plt.figure(constrained_layout=True, figsize=(base_size*n_t_display,base_size*timecourse_plot_rel_height))\n",
        "    gs = fig.add_gridspec(timecourse_plot_rel_height+1, n_t_display)\n",
        "    tc_ax = fig.add_subplot(gs[:-1,:])\n",
        "    rdm_axes = [fig.add_subplot(gs[-1,i]) for i in range(n_t_display)]\n",
        "\n",
        "    # plot dissimilarity timecourses\n",
        "    lines = []\n",
        "\n",
        "    dissimilarities_mean = np.zeros((rdms_data.dissimilarities.shape[1], len(unique_time)))\n",
        "    dissimilarities_sem = np.zeros((rdms_data.dissimilarities.shape[1], len(unique_time)))\n",
        "\n",
        "    for i, t in enumerate(unique_time):\n",
        "        dissimilarities_mean[:, i] = np.mean(rdms_data.dissimilarities[t == times, :], axis=0)\n",
        "\n",
        "    def _plot_mean_dissimilarities(labels=False):\n",
        "        for i, (pairwise_name, idx) in enumerate(color_index.items()):\n",
        "            mn = np.mean(dissimilarities_mean[idx, :],axis=0)\n",
        "            se = np.std(dissimilarities_mean[idx, :],axis=0)/ np.sqrt(dissimilarities_mean.shape[0]) # se is over dissimilarities, not over subjects\n",
        "            tc_ax.fill_between(unique_time, mn-se, mn+se, color=colors[i], alpha=.3)\n",
        "            tc_ax.plot(unique_time, mn, color=colors[i], linewidth=2, label=pairwise_name if labels else None)\n",
        "\n",
        "    def _plot_individual_dissimilarities():\n",
        "        for i, (pairwise_name, idx) in enumerate(color_index.items()):\n",
        "            tc_ax.plot(unique_time, dissimilarities_mean[idx, :].T, color=colors[i], alpha=max(1/255., 1/n_dissimilarity_elements))\n",
        "\n",
        "    if plot_individual_dissimilarities:\n",
        "        if colored_conditions is not None:\n",
        "            _plot_mean_dissimilarities()\n",
        "            yl = tc_ax.get_ylim()\n",
        "            _plot_individual_dissimilarities()\n",
        "            tc_ax.set_ylim(yl)\n",
        "        else:\n",
        "            _plot_individual_dissimilarities()\n",
        "\n",
        "    if colored_conditions is not None:\n",
        "        _plot_mean_dissimilarities(True)\n",
        "\n",
        "    yl = tc_ax.get_ylim()\n",
        "    for t in unique_time[t_display_idx]:\n",
        "        tc_ax.plot([t,t], yl, linestyle=':', color='b', alpha=0.3)\n",
        "    tc_ax.set_ylabel(f'Dissimilarity\\n({rdms_data.dissimilarity_measure})')\n",
        "    tc_ax.set_xticks(unique_time)\n",
        "    tc_ax.set_xticklabels([time_formatted[idx]  if idx in t_display_idx else '' for idx in range(len(unique_time))])\n",
        "    dt = np.diff(unique_time[t_display_idx])[0]\n",
        "    tc_ax.set_xlim(unique_time[t_display_idx[0]]-dt/2, unique_time[t_display_idx[-1]]+dt/2)\n",
        "\n",
        "    tc_ax.legend()\n",
        "\n",
        "    # display (selected) rdms\n",
        "    vmax = np.std(rdms_data.dissimilarities) * 2\n",
        "    for i, (tidx, a) in enumerate(zip(t_display_idx, rdm_axes)):\n",
        "        a.imshow(np.mean(rdms_data.subset('time', times[tidx]).get_matrices(),axis=0), vmin=0, vmax=vmax);\n",
        "        a.set_title('%0.0f ms' % (np.round(unique_time[tidx]*1000,2)))\n",
        "        a.set_yticklabels([])\n",
        "        a.set_yticks([])\n",
        "        a.set_xticklabels([])\n",
        "        a.set_xticks([])\n",
        "\n",
        "    return fig, [tc_ax] + rdm_axes"
      ],
      "metadata": {
        "id": "x_76ctUgcMgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the RDMs"
      ],
      "metadata": {
        "id": "eRrC8FMXdsQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plot_rdm_movie(\n",
        "                         rdms,\n",
        "                         descriptor=None,\n",
        "                         n_t_display=10,\n",
        "                         fig_width=20,\n",
        "                         colored_conditions=None,\n",
        "                        );"
      ],
      "metadata": {
        "id": "4aHPXlpPcNlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate MEG RDMs similarity to CNN RDM"
      ],
      "metadata": {
        "id": "1gSmiKGUeH5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.fill_diagonal(rdm_dnn,0)\n",
        "model_rdm = rsatoolbox.rdm.RDMs(dissimilarities=squareform(rdm_dnn))\n",
        "\n",
        "results = rsatoolbox.rdm.compare(model_rdm, rdms, method='corr')"
      ],
      "metadata": {
        "id": "x8FdZKDJeOWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the result"
      ],
      "metadata": {
        "id": "VPSP1kSmPIj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(181), results.squeeze())"
      ],
      "metadata": {
        "id": "H3RHThHM_vtF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}